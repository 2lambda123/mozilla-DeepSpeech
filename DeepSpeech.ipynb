{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will reproduce the results of [Deep Speech: Scaling up end-to-end speech recognition](http://arxiv.org/abs/1412.5567). The core of the system is a bidirectional recurrent neural network (BRNN) trained to ingest speech spectrograms and generate English text transcriptions.\n",
    "\n",
    " Let a single utterance $x$ and label $y$ be sampled from a training set $S = \\{(x^{(1)}, y^{(1)}), (x^{(2)}, y^{(2)}), . . .\\}$. Each utterance, $x^{(i)}$ is a time-series of length $T^{(i)}$ where every time-slice is a vector of audio features, $x^{(i)}_t$ where $t=1,\\ldots,T^{(i)}$. We use MFCC as our features; so $x^{(i)}_{t,p}$ denotes the $p$-th MFCC feature in the audio frame at time $t$. The goal of our BRNN is to convert an input sequence $x$ into a sequence of character probabilities for the transcription $y$, with $\\hat{y}_t =\\mathbb{P}(c_t \\mid x)$, where $c_t \\in \\{a,b,c, . . . , z, space, apostrophe, blank\\}$. (The significance of $blank$ will be explained below.)\n",
    "\n",
    "Our BRNN model is composed of $5$ layers of hidden units. For an input $x$, the hidden units at layer $l$ are denoted $h^{(l)}$ with the convention that $h^{(0)}$ is the input. The first three layers are not recurrent. For the first layer, at each time $t$, the output depends on the MFCC frame $x_t$ along with a context of $C$ frames on each side. (We typically use $C \\in \\{5, 7, 9\\}$ for our experiments.) The remaining non-recurrent layers operate on independent data for each time step. Thus, for each time $t$, the first $3$ layers are computed by:\n",
    "\n",
    "$$h^{(l)}_t = g(W^{(l)} h^{(l-1)}_t + b^{(l)})$$\n",
    "\n",
    "where $g(z) = \\min\\{\\max\\{0, z\\}, 20\\}$ is a clipped rectified-linear (ReLu) activation function and $W^{(l)}$, $b^{(l)}$ are the weight matrix and bias parameters for layer $l$. The fourth layer is a bidirectional recurrent layer[[1](http://www.di.ufpe.br/~fnj/RNA/bibliografia/BRNN.pdf)]. This layer includes two sets of hidden units: a set with forward recurrence, $h^{(f)}$, and a set with backward recurrence $h^{(b)}$:\n",
    "\n",
    "$$h^{(f)}_t = g(W^{(4)} h^{(3)}_t + W^{(f)}_r h^{(f)}_{t-1} + b^{(4)})$$\n",
    "$$h^{(b)}_t = g(W^{(4)} h^{(3)}_t + W^{(b)}_r h^{(b)}_{t+1} + b^{(4)})$$\n",
    "\n",
    "Note that $h^{(f)}$ must be computed sequentially from $t = 1$ to $t = T^{(i)}$ for the $i$-th utterance, while\n",
    "the units $h^{(b)}$ must be computed sequentially in reverse from $t = T^{(i)}$ to $t = 1$.\n",
    "\n",
    "The fifth (non-recurrent) layer takes both the forward and backward units as inputs\n",
    "\n",
    "$$h^{(5)} = g(W^{(5)} h^{(4)} + b^{(5)})$$\n",
    "\n",
    "where $h^{(4)} = h^{(f)} + h^{(b)}$. The output layer are standard logits that correspond to the predicted character probabilities for each time slice $t$ and character $k$ in the alphabet:\n",
    "\n",
    "$$h^{(6)}_{t,k} = \\hat{y}_{t,k} = (W^{(6)} h^{(5)}_t)_k + b^{(6)}_k$$\n",
    "\n",
    "Here $b^{(6)}_k$ denotes the $k$-th bias and $(W^{(6)} h^{(5)}_t)_k$ the $k$-th element of the matrix product.\n",
    "\n",
    "Once we have computed a prediction for $\\hat{y}_{t,k}$, we compute the CTC loss[[2]](http://www.cs.toronto.edu/~graves/preprint.pdf) $\\cal{L}(\\hat{y}, y)$ to measure the error in prediction. During training, we can evaluate the gradient $\\nabla \\cal{L}(\\hat{y}, y)$ with respect to the network outputs given the ground-truth character sequence $y$. From this point, computing the gradient with respect to all of the model parameters may be done via back-propagation through the rest of the network. We use the Adam method for training[[3](http://arxiv.org/abs/1412.6980)].\n",
    "\n",
    "The complete BRNN model is illustrated in the figure below.\n",
    "\n",
    "![DeepSpeech BRNN](images/rnn_fig-624x548.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we first import all of the packages we require to implement the DeepSpeech BRNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from tensorflow.python.ops import ctc_ops\n",
    "from tensorflow.python.ops import variables as vs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we introduce several constants used in the algorithm below.  In particular, we define\n",
    "* `learning_rate` - The learning rate we will employ in Adam optimizer[[3]](http://arxiv.org/abs/1412.6980)\n",
    "* `training_iters`- The number of iterations we will train for\n",
    "* `batch_size`- The number of elements in a batch\n",
    "* `display_step`- The number of iterations we cycle through before displaying progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001   # TODO: Determine a reasonable value for this\n",
    "beta1 = 0.9             # TODO: Determine a reasonable value for this\n",
    "beta2 = 0.999           # TODO: Determine a reasonable value for this\n",
    "epsilon = 1e-8          # TODO: Determine a reasonable value for this\n",
    "training_iters = 100    # TODO: Determine a reasonable value for this\n",
    "batch_size = 1          # TODO: Determine a reasonable value for this\n",
    "display_step = 1        # TODO: Determine a reasonable value for this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we use the Adam optimizer[[3]](http://arxiv.org/abs/1412.6980) instead of Nesterov’s Accelerated Gradient [[4]](http://www.cs.utoronto.ca/~ilya/pubs/2013/1051_2.pdf) used in the original DeepSpeech paper, as, at the time of writing, TensorFlow does not have an implementation of Nesterov’s Accelerated Gradient [[4]](http://www.cs.utoronto.ca/~ilya/pubs/2013/1051_2.pdf).\n",
    "\n",
    "As we will also employ dropout on the feedforward layers of the network, we need to define a parameter `dropout_rate` that keeps track of the dropout rate for these layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dropout_rate = 0.05  # TODO: Validate this is a reasonable value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One more constant required of the non-recurrant layers is the clipping value of the ReLU. We capture that in the value of the variable `relu_clip`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "relu_clip = 20 # TODO: Validate this is a reasonable value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geometric Constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will introduce several constants related to the geometry of the network.\n",
    "\n",
    "The network views each speech sample as a sequence of time-slices $x^{(i)}_t$ of length $T^{(i)}$. As the speech samples vary in length, we know that $T^{(i)}$ need not equal $T^{(j)}$ for $i \\ne j$. However, BRNN in TensorFlow are unable to deal with sequences with differing lengths. Thus, we must pad speech sample sequences with trailing zeros such that they are all of the same length. This common padded length is captured in the variable `n_steps` which will be set after the data set is loaded. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of the `n_steps` vectors is MFCC features of a time-slice of the speech sample. We will make the number of MFCC features dependent upon the sample rate of the data set. Generically, if the sample rate is 8kHz we use 13 features. If the sample rate is 16kHz we use 26 features... We capture the dimension of these vectors, equivalently the number of MFCC features, in the variable `n_input`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_input = 26 # TODO: Determine this programatically from the sample rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As previously mentioned, the BRNN is not simply fed the MFCC features of a given time-slice. It is fed, in addition, a context of $C \\in \\{5, 7, 9\\}$ frames on either side of the frame in question. The number of frames in this context is captured in the variable `n_context`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_context = 5 # TODO: Determine the optimal value using a validation data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will introduce constants that specify the geometry of some of the non-recurrent layers of the network. We do this by simply specifying the number of units in each of the layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_hidden_1 = n_input + 2*n_input*n_context # Note: This value was not specified in the original paper\n",
    "n_hidden_2 = n_input + 2*n_input*n_context # Note: This value was not specified in the original paper\n",
    "n_hidden_5 = n_input + 2*n_input*n_context # Note: This value was not specified in the original paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where `n_hidden_1` is the number of units in the first layer, `n_hidden_2` the number of units in the second, and  `n_hidden_5` the number in the fifth. We haven't forgotten about the third or sixth layer. We will define their unit count below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A LSTM BRNN consists of a pair of LSTM RNN's. One LSTM RNN that works \"forward in time\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/LSTM3-chain.png\" alt=\"LSTM\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and a second LSTM RNN that works \"backwards in time\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/LSTM3-chain.png\" alt=\"LSTM\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dimension of the cell state, the upper line connecting subsequent LSTM units, is independent of the input dimension and the same for both the forward and backward LSTM RNN.\n",
    "\n",
    "Hence, we are free to choose the dimension of this cell state independent of the input dimension. We capture the cell state dimension in the variable `n_cell_dim`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_cell_dim = n_input + 2*n_input*n_context # TODO: Is this a reasonable value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of units in the third layer, which feeds in to the LSTM, is determined by `n_cell_dim` as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_hidden_3 = 2 * n_cell_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we introduce an additional variable `n_character` which holds the number of characters in the target language plus one, for the $blamk$. For English it is the cardinality of the set $\\{a,b,c, . . . , z, space, apostrophe, blank\\}$ we referred to earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_character = 29 # TODO: Determine if this should be extended with other punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of units in the sixth layer is determined by `n_character` as follows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_hidden_6 = n_character"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will import the [TED-LIUM](http://www-lium.univ-lemans.fr/en/content/ted-lium-corpus) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from util.importers.ted_lium import read_data_sets\n",
    "ted_lium = read_data_sets('./data/smoke_test', n_input, n_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have loaded the data we can set the `n_steps` paramater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_steps = ted_lium.train.max_batch_seq_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we concern ourselves with graph creation.\n",
    "\n",
    "First we create several place holders in our graph. The first two `x` and `y` are placeholders for our training data pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(\"float\", [None, n_steps, n_input + 2*n_input*n_context])\n",
    "y = tf.sparse_placeholder(tf.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The placeholder `y` represents the text transcript of each element in a batch. `y` is of type \"SparseTensor\" required by the CTC algorithm. The details of how the text transcripts are encoded in to a \"SparseTensor\" will be presented below.\n",
    "\n",
    "The placeholder `x` is a place holder for the speech features along with their prefix and postfix contexts for each element in a batch. As it represents MFCC features, its type is \"float\". The `None` dimension of its shape\n",
    "\n",
    "```python\n",
    "[None, n_steps, n_input + 2*n_input*n_context]\n",
    "```\n",
    "\n",
    "is a 'placeholder' for the batch size. The `n_steps` dimension of its shape indicates the number of time-slices in the sequence. Finally, the `n_input + 2*n_input*n_context` dimension of its shape indicates the number of MFCC features `n_input` along with the number of MFCC features in the prefix-context `n_input*n_context` and postfix-contex `n_input*n_context`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next placeholder is for the sequence lengths of the elements in each batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seq_len = tf.placeholder(tf.int32, [None])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `None` dimension of the placeholder `seq_len`, as in the case of the placeholders `x` and `y`, is a 'placeholder' for the batch size. So, `seq_len` is a placeholder for a vector of 32 bit integers. Each one of these 32 bit integers holds the length of the corresponding element in the batch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we will be employing dropout on the feedforward layers of the network we will also introduce a placeholder `keep_prob` which is a placeholder for the dropout rate for the feedforward layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will define the learned variables through two dictionaries. The first dictionary `weights` holds the learned weight variables. The second `biases` holds the learned bias variables.\n",
    "\n",
    "The `weights` dictionary has the keys `'h1'`, `'h2'`, `'h3'`, `'h5'`, and `'h6'` each keyed against the values of the corresponding weight matrix. In particular, the first key `'h1'` is keyed against a value which is the learned weight matrix that converts an input vector of dimension `n_input + 2*n_input*n_context`  to a vector of dimension `n_hidden_1`. Similarly, the second key `'h2'` is keyed against a value which is the weight matrix converting an input vector of dimension `n_hidden_1` to one of dimension `n_hidden_2`. The keys `'h3'`, `'h5'`, and `'h6'` are similar. Likewise, the `biases` dictionary has biases for the various layers.\n",
    "\n",
    "Concretely these dictionaries are given by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Store layers weight & bias\n",
    "# TODO: Is random_normal the best distribution to draw from?\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_input + 2*n_input*n_context, n_hidden_1]), name=\"h1\"),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2]), name=\"h2\"),\n",
    "    'h3': tf.Variable(tf.random_normal([n_hidden_2, n_hidden_3]), name=\"h3\"),\n",
    "    'h5': tf.Variable(tf.random_normal([(2 * n_cell_dim), n_hidden_5]), name=\"h5\"),\n",
    "    'h6': tf.Variable(tf.random_normal([n_hidden_5, n_hidden_6]), name=\"h6\")\n",
    "}\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1]), name=\"b1\"),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2]), name=\"b2\"),\n",
    "    'b3': tf.Variable(tf.random_normal([n_hidden_3]), name=\"b3\"),\n",
    "    'b5': tf.Variable(tf.random_normal([n_hidden_5]), name=\"b5\"),\n",
    "    'b6': tf.Variable(tf.random_normal([n_hidden_6]), name=\"b6\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we introduce a utility function `BiRNN` that can take the placeholder `x` along with the dictionaries `weights` and `biases` and add all the apropos operators to our default graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def BiRNN(_X, _weights, _biases):\n",
    "    # Input shape: [batch_size, n_steps, n_input + 2*n_input*n_context]\n",
    "    _X = tf.transpose(_X, [1, 0, 2])  # Permute n_steps and batch_size\n",
    "    # Reshape to prepare input for first layer\n",
    "    _X = tf.reshape(_X, [-1, n_input + 2*n_input*n_context]) # (n_steps*batch_size, n_input + 2*n_input*n_context)\n",
    "    \n",
    "    #Hidden layer with clipped RELU activation and dropout\n",
    "    layer_1 = tf.minimum(tf.nn.relu(tf.add(tf.matmul(_X, _weights['h1']), _biases['b1'])), relu_clip)\n",
    "    layer_1 = tf.nn.dropout(layer_1, keep_prob)\n",
    "    #Hidden layer with clipped RELU activation and dropout\n",
    "    layer_2 = tf.minimum(tf.nn.relu(tf.add(tf.matmul(layer_1, _weights['h2']), _biases['b2'])), relu_clip)\n",
    "    layer_2 = tf.nn.dropout(layer_2, keep_prob)\n",
    "    #Hidden layer with clipped RELU activation and dropout\n",
    "    layer_3 = tf.minimum(tf.nn.relu(tf.add(tf.matmul(layer_2, _weights['h3']), _biases['b3'])), relu_clip)\n",
    "    layer_3 = tf.nn.dropout(layer_3, keep_prob)\n",
    "    \n",
    "    # Define lstm cells with tensorflow\n",
    "    # Forward direction cell\n",
    "    lstm_fw_cell = tf.nn.rnn_cell.BasicLSTMCell(n_cell_dim, forget_bias=1.0)\n",
    "    # Backward direction cell\n",
    "    lstm_bw_cell = tf.nn.rnn_cell.BasicLSTMCell(n_cell_dim, forget_bias=1.0)\n",
    "    \n",
    "    # Split data because rnn cell needs a list of inputs for the BRNN inner loop\n",
    "    layer_3 = tf.split(0, n_steps, layer_3)\n",
    "    \n",
    "    # Get lstm cell output\n",
    "    outputs, output_state_fw, output_state_bw = tf.nn.bidirectional_rnn(cell_fw=lstm_fw_cell,\n",
    "                                                                        cell_bw=lstm_bw_cell,\n",
    "                                                                        inputs=layer_3,\n",
    "                                                                        dtype=tf.float32)\n",
    "    \n",
    "    # Reshape outputs from a list of n_steps tensors each of shape [batch_size, 2*n_cell_dim]\n",
    "    # to a single tensor of shape [n_steps*batch_size, 2*n_cell_dim]\n",
    "    outputs = tf.pack(outputs)\n",
    "    outputs = tf.reshape(outputs, [-1, 2*n_cell_dim])\n",
    "    \n",
    "    #Hidden layer with clipped RELU activation and dropout\n",
    "    layer_5 = tf.minimum(tf.nn.relu(tf.add(tf.matmul(outputs, _weights['h5']), _biases['b5'])), relu_clip)\n",
    "    layer_5 = tf.nn.dropout(layer_5, keep_prob)\n",
    "    #Hidden layer of logits\n",
    "    layer_6 = tf.add(tf.matmul(layer_5, _weights['h6']), _biases['b6'])\n",
    "    \n",
    "    # Reshape layer_6 from a tensor of shape [n_steps*batch_size, n_hidden_6]\n",
    "    # to a tensor of shape [batch_size, n_steps, n_hidden_6]\n",
    "    layer_6 = tf.reshape(layer_6, [n_steps, batch_size, n_hidden_6])\n",
    "    layer_6 = tf.transpose(layer_6, [1, 0, 2])  # Permute n_steps and batch_size\n",
    "    \n",
    "    # Return layer_6\n",
    "    return layer_6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first few lines of the function `BiRNN`\n",
    "```python\n",
    "def BiRNN(_X, _weights, _biases):\n",
    "    # Input shape: [batch_size, n_steps, n_input + 2*n_input*n_context]\n",
    "    _X = tf.transpose(_X, [1, 0, 2])  # Permute n_steps and batch_size\n",
    "    # Reshape to prepare input for first layer\n",
    "    _X = tf.reshape(_X, [-1, n_input + 2*n_input*n_context])\n",
    "    ...\n",
    "```\n",
    "reshape `_X` which has shape `[batch_size, n_steps, n_input + 2*n_input*n_context]` initially, to a tensor with shape `[n_steps*batch_size, n_input + 2*n_input*n_context]`. This is done to prepare the batch for input into the first layer which expects a tensor of rank `2`.\n",
    "\n",
    "The next few lines of  `BiRNN`\n",
    "```python\n",
    "    #Hidden layer with clipped RELU activation and dropout\n",
    "    layer_1 = tf.minimum(tf.nn.relu(tf.add(tf.matmul(_X, _weights['h1']), _biases['b1'])), relu_clip)\n",
    "    layer_1 = tf.nn.dropout(layer_1, keep_prob)\n",
    "    ...\n",
    "```\n",
    "pass `_X` through the first layer of the non-recurrent neural network, then apply dropout to the result.\n",
    "\n",
    "The next few lines do the same thing, but for the second and third layers\n",
    "```python\n",
    "    #Hidden layer with clipped RELU activation and dropout\n",
    "    layer_2 = tf.minimum(tf.nn.relu(tf.add(tf.matmul(layer_1, _weights['h2']), _biases['b2'])), relu_clip)\n",
    "    layer_2 = tf.nn.dropout(layer_2, keep_prob)\n",
    "    #Hidden layer with clipped RELU activation and dropout\n",
    "    layer_3 = tf.minimum(tf.nn.relu(tf.add(tf.matmul(layer_2, _weights['h3']), _biases['b3'])), relu_clip)\n",
    "    layer_3 = tf.nn.dropout(layer_3, keep_prob)\n",
    "```\n",
    "\n",
    "Next we create the forward and backward LSTM units\n",
    "```python\n",
    "    # Define lstm cells with tensorflow\n",
    "    # Forward direction cell\n",
    "    lstm_fw_cell = tf.nn.rnn_cell.BasicLSTMCell(n_cell_dim, forget_bias=1.0)\n",
    "    # Backward direction cell\n",
    "    lstm_bw_cell = tf.nn.rnn_cell.BasicLSTMCell(n_cell_dim, forget_bias=1.0)\n",
    "```\n",
    "both of which have inputs of length `n_cell_dim` and bias `1.0` for the forget gate of the LSTM.\n",
    "\n",
    "The next line of the funtion `BiRNN` does a bit more data preparation.\n",
    "```python\n",
    "    # Split data because rnn cell needs a list of inputs for the RNN inner loop\n",
    "    layer_3 = tf.split(0, n_steps, layer_3)\n",
    "```\n",
    "It splits `layer_3` in to `n_steps` tensors along dimension `0` as the LSTM BRNN expects its input to be of shape `n_steps *[batch_size, 2*n_cell_dim]`.\n",
    "\n",
    "The next line of `BiRNN`\n",
    "```python\n",
    "    # Get lstm cell output\n",
    "    outputs, output_state_fw, output_state_bw  = tf.nn.bidirectional_rnn(cell_fw=lstm_fw_cell,\n",
    "                                                                         cell_bw=lstm_bw_cell,\n",
    "                                                                         inputs=layer_3,\n",
    "                                                                         dtype=tf.float32)\n",
    "```\n",
    "feeds `layer_3` to the LSTM BRNN cell and obtains the LSTM BRNN output.\n",
    "\n",
    "The next lines convert `outputs` from a list of rank two tensors into a single rank two tensor in preparation for passing it to the next neural network layer  \n",
    "```python\n",
    "    # Reshape outputs from a list of n_steps tensors each of shape [batch_size, 2*n_cell_dim]\n",
    "    # to a single tensor of shape [n_steps*batch_size, 2*n_cell_dim]\n",
    "    outputs = tf.pack(outputs)\n",
    "    outputs = tf.reshape(outputs, [-1, 2*n_cell_dim])\n",
    "```\n",
    "\n",
    "The next couple of lines feed `outputs` to the fifth hidden layer\n",
    "```python\n",
    "    #Hidden layer with clipped RELU activation and dropout\n",
    "    layer_5 = tf.minimum(tf.nn.relu(tf.add(tf.matmul(outputs, _weights['h5']), _biases['b5'])), relu_clip)\n",
    "    layer_5 = tf.nn.dropout(layer_5, keep_prob)\n",
    "```\n",
    "\n",
    "The next line of `BiRNN`\n",
    "```python\n",
    "    #Hidden layer of logits\n",
    "    layer_6 = tf.add(tf.matmul(layer_5, _weights['h6']), _biases['b6'])\n",
    "```\n",
    "Applies the weight matrix `_weights['h6']` and bias `_biases['h6']`to the output of `layer_5` creating `n_classes` dimensional vectors, the logits.\n",
    "\n",
    "The next lines of `BiRNN`\n",
    "```python\n",
    "    # Reshape layer_6 from a tensor of shape [n_steps*batch_size, n_hidden_6]\n",
    "    # to a tensor of shape [batch_size, n_steps, n_hidden_6]\n",
    "    layer_6 = tf.reshape(layer_6, [n_steps, batch_size, n_hidden_6])\n",
    "    layer_6 = tf.transpose(layer_6, [1, 0, 2])  # Permute n_steps and batch_size\n",
    "```\n",
    "reshapes `layer_6` to the slightly more useful shape `[batch_size, n_steps, n_hidden_6]`.\n",
    "\n",
    "The final line of `BiRNN` returns `layer_6`\n",
    "```python\n",
    "    # Return layer_6\n",
    "    return layer_6\n",
    "```\n",
    "\n",
    "Next we actually call `BiRNN` with the apropos data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "layer_6 = BiRNN(x, weights, biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In accord with [Deep Speech: Scaling up end-to-end speech recognition](http://arxiv.org/abs/1412.5567), the loss function used by our network should be the CTC loss function[[2]](http://www.cs.toronto.edu/~graves/preprint.pdf). Conveniently, this loss function is implemented in TensorFlow. Thus, we can simply make use of this implementation to define our loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# CTC loss requires layer_6 be time major\n",
    "layer_6 = tf.transpose(layer_6, [1, 0, 2])\n",
    "\n",
    "# Compute the CTC loss\n",
    "total_loss = ctc_ops.ctc_loss(layer_6, y, seq_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, instead of using the total loss for the entire batch we want to calculate the average loss across the batch to facilitate comparing results as the batch size varies. So we calculate the following "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "avg_loss = tf.reduce_mean(total_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In constrast to [Deep Speech: Scaling up end-to-end speech recognition](http://arxiv.org/abs/1412.5567), in which  [Nesterov’s Accelerated Gradient Descent](www.cs.toronto.edu/~fritz/absps/momentum.pdf) was used, we will use the Adam method for optimization[[3](http://arxiv.org/abs/1412.6980)], because, generally, it requires less fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate,\n",
    "                                   beta1=beta1,\n",
    "                                   beta2=beta2,\n",
    "                                   epsilon=epsilon)\n",
    "gradients = optimizer.compute_gradients(avg_loss)\n",
    "minimize = optimizer.apply_gradients(gradients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next to monitor training progress we will intoduce an operator used to decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "decoded, _ = ctc_ops.ctc_beam_search_decoder(layer_6, seq_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this decoding operator we can then calculate the CER, otherwise known as accuracy, of the system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "acc = tf.reduce_mean(tf.edit_distance(tf.cast(decoded[0], tf.int32), y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def log_variable (variable):\n",
    "    name = variable.name\n",
    "    mean = tf.reduce_mean(variable)\n",
    "    tf.scalar_summary(name + '/mean', mean)\n",
    "    tf.scalar_summary(name + '/sttdev', tf.sqrt(tf.reduce_mean(tf.square(variable - mean))))\n",
    "    tf.scalar_summary(name + '/max', tf.reduce_max(variable))\n",
    "    tf.scalar_summary(name + '/min', tf.reduce_min(variable))\n",
    "    tf.histogram_summary(name, variable)\n",
    "    tf.histogram_summary(name + \"/gradients\", grad_values)\n",
    "\n",
    "for gradient, variable in gradients:\n",
    "    if isinstance(gradient, tf.IndexedSlices):\n",
    "        grad_values = gradient.values\n",
    "    else:\n",
    "        grad_values = gradient\n",
    "    if grad_values is not None:\n",
    "        print(variable.name)\n",
    "        log_variable(variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will begin the process of training the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "with tf.Session() as session:\n",
    "    # Initialize all variables\n",
    "    tf.initialize_all_variables().run()\n",
    "    merged = tf.merge_all_summaries()\n",
    "    writer = tf.train.SummaryWriter('%s/%s' % (\"logs\", time.strftime(\"%Y%m%d-%H%M%S\")), session.graph)\n",
    "    \n",
    "    # Loop over the data set for training_epochs epochs\n",
    "    for epoch in range(training_iters):\n",
    "        # Define total_loss\n",
    "        total_loss = 0\n",
    "        \n",
    "        # Define character error rate\n",
    "        train_cer = 0\n",
    "        \n",
    "        # Determine the total number of batches\n",
    "        total_batch = int(ted_lium.train.num_examples/batch_size)\n",
    "        \n",
    "        # Loop over the batches\n",
    "        for batch in range(total_batch):\n",
    "            # Obtain the next batch of data\n",
    "            batch_x, batch_y, batch_seq_len = ted_lium.train.next_batch(batch_size)\n",
    "            \n",
    "            # Create a map to fill the placeholders with batch data\n",
    "            feed = {x: batch_x,\n",
    "                    y: batch_y,\n",
    "                    seq_len: batch_seq_len,\n",
    "                    keep_prob: (1 - dropout_rate)}\n",
    "            \n",
    "            # Train on the current batch\n",
    "            batch_avg_loss, _ = session.run([avg_loss, minimize], feed)\n",
    "            train_cer += session.run(acc, feed_dict=feed)\n",
    "\n",
    "            summary_str = session.run(merged, feed_dict=feed)\n",
    "            writer.add_summary(summary_str, epoch * batch_size + batch)\n",
    "            writer.flush()\n",
    "    \n",
    "            # Add batch_avg_loss to total_loss\n",
    "            total_loss += batch_avg_loss\n",
    "            \n",
    "        if epoch % display_step == 0:\n",
    "            print \"Epoch:\", '%04d' % (epoch+1), \"avg_cer=\", \"{:.9f}\".format((train_cer / total_batch))\n",
    "\n",
    "    # Indicate optimization has concluded\n",
    "    print \"Optimization Finished!\"\n",
    "    \n",
    "    # Decoding\n",
    "    d = session.run(decoded[0], feed_dict=feed)\n",
    "    str_decoded = ''.join([chr(xt) for xt in np.asarray(d[1]) + (ord('a') - 1 )])\n",
    "    # Replacing blank label to none\n",
    "    str_decoded = str_decoded.replace(chr(ord('z') + 1), '')\n",
    "    # Replacing space label to space\n",
    "    str_decoded = str_decoded.replace(chr(ord('a') - 1), ' ')\n",
    "    print('Decoded:\\n%s' % str_decoded)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
